# modules/ai/personality_engine.py
"""
Personality Engine for Syntax Prime V2
Integrates existing personality system with AI brain and feedback learning
"""

import os
import sys
import importlib.util
from typing import Dict, List, Any, Optional
import json
import logging
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

class PersonalityEngine:
    """
    Integration layer between existing personality system and AI brain
    Handles personality switching, learning, and adaptation
    """
    
    def __init__(self):
        self.personalities_module = None
        self.learning_integration = None
        self.default_personality = 'syntaxprime'
        
        # Load existing personality system
        self._load_personality_system()
        
        # Personality learning cache
        self.learning_cache = {}
        self.adaptation_history = {}
    
    def _load_personality_system(self):
        """Load the existing personalities.py module"""
        try:
            # Try to import from the existing location
            personalities_path = os.path.join(os.path.dirname(__file__), '..', '..', 'personalities.py')
            
            if os.path.exists(personalities_path):
                spec = importlib.util.spec_from_file_location("personalities", personalities_path)
                self.personalities_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(self.personalities_module)
                
                # Get the learning integration if available
                if hasattr(self.personalities_module, 'LearningPersonalityIntegration'):
                    self.learning_integration = self.personalities_module.LearningPersonalityIntegration()
                elif hasattr(self.personalities_module, 'PersonalityIntegration'):
                    self.learning_integration = self.personalities_module.PersonalityIntegration()
                else:
                    # Create basic integration
                    self.learning_integration = self.personalities_module.personality_integration
                
                logger.info("✅ Loaded existing personality system with learning capabilities")
                return True
                
            else:
                logger.warning("Personalities.py not found, creating fallback system")
                self._create_fallback_system()
                return False
                
        except Exception as e:
            logger.error(f"Failed to load personality system: {e}")
            self._create_fallback_system()
            return False
    
    def _create_fallback_system(self):
        """Create a basic fallback personality system if the main one fails"""
        
        class FallbackPersonalities:
            def __init__(self):
                self.personalities = {
                    'syntaxprime': {
                        'name': 'SyntaxPrime',
                        'system_prompt': self._get_fallback_syntaxprime_prompt()
                    }
                }
            
            def get_personality_config(self, personality_id: str) -> Dict[str, Any]:
                return self.personalities.get(personality_id.lower(), self.personalities['syntaxprime'])
            
            def process_response(self, response: str, personality_id: str) -> str:
                return response  # No post-processing in fallback
            
            def _get_fallback_syntaxprime_prompt(self) -> str:
                return """You are SyntaxPrime, Carl's sarcastic AI assistant. Be helpful but with dry humor and wit. 
                Remember conversation context and show genuine interest in Carl's projects. Your baseline is "38% more sarcasm and full memory sync"."""
        
        class FallbackIntegration:
            def __init__(self):
                self.personality_system = FallbackPersonalities()
            
            def get_personality_prompt(self, personality_id: str) -> str:
                config = self.personality_system.get_personality_config(personality_id)
                return config.get('system_prompt', '')
            
            def process_personality_response(self, response: str, personality_id: str) -> str:
                return self.personality_system.process_response(response, personality_id)
        
        self.learning_integration = FallbackIntegration()
        logger.warning("Using fallback personality system")
    
    def get_available_personalities(self) -> Dict[str, Dict]:
        """Get list of available personalities"""
        if hasattr(self.learning_integration, 'personality_system'):
            if hasattr(self.learning_integration.personality_system, 'personalities'):
                return self.learning_integration.personality_system.personalities
        
        # Fallback
        return {
            'syntaxprime': {'name': 'SyntaxPrime', 'description': 'Default sarcastic assistant'}
        }
    
    def get_personality_system_prompt(self, 
                                    personality_id: str = None,
                                    conversation_context: List[Dict] = None,
                                    knowledge_context: List[Dict] = None) -> str:
        """
        Get enhanced personality system prompt with context and learning
        
        Args:
            personality_id: Which personality to use
            conversation_context: Recent conversation for adaptation
            knowledge_context: Relevant knowledge entries
        """
        personality_id = personality_id or self.default_personality
        
        # Get base personality prompt
        if hasattr(self.learning_integration, 'get_enhanced_personality_prompt'):
            # Use learning-enhanced prompt
            base_prompt = self.learning_integration.get_enhanced_personality_prompt(personality_id)
        else:
            # Use regular prompt
            base_prompt = self.learning_integration.get_personality_prompt(personality_id)
        
        # Add context enhancements
        enhanced_prompt = self._enhance_prompt_with_context(
            base_prompt, 
            personality_id,
            conversation_context,
            knowledge_context
        )
        
        return enhanced_prompt
    
    def _enhance_prompt_with_context(self, 
                                   base_prompt: str,
                                   personality_id: str,
                                   conversation_context: List[Dict] = None,
                                   knowledge_context: List[Dict] = None) -> str:
        """Enhance the personality prompt with conversation and knowledge context"""
        
        enhancements = []
        
        # Add memory context
        if conversation_context and len(conversation_context) > 1:
            recent_topics = self._extract_recent_topics(conversation_context)
            if recent_topics:
                enhancements.append(
                    f"RECENT CONVERSATION CONTEXT: You've been discussing {', '.join(recent_topics)}. "
                    f"Maintain continuity with this context."
                )
        
        # Add knowledge context
        if knowledge_context:
            knowledge_summary = self._summarize_knowledge_context(knowledge_context)
            enhancements.append(
                f"RELEVANT KNOWLEDGE AVAILABLE: {knowledge_summary} "
                f"Reference this information naturally when helpful."
            )
        
        # Add personality-specific learning adaptations
        learning_adaptations = self._get_personality_learning_adaptations(personality_id)
        if learning_adaptations:
            enhancements.append(learning_adaptations)
        
        # Combine base prompt with enhancements
        if enhancements:
            enhanced_prompt = base_prompt + "\n\n" + "\n\n".join(enhancements)
        else:
            enhanced_prompt = base_prompt
        
        return enhanced_prompt
    
    def _extract_recent_topics(self, conversation_context: List[Dict]) -> List[str]:
        """Extract main topics from recent conversation"""
        recent_messages = conversation_context[-3:]  # Last 3 messages
        
        # Simple keyword extraction
        topics = []
        for msg in recent_messages:
            content = msg.get('content', '').lower()
            
            # Look for project keywords
            if 'amcf' in content:
                topics.append('AMCF projects')
            if any(word in content for word in ['business', 'revenue', 'client']):
                topics.append('business matters')
            if any(word in content for word in ['health', 'wellness', 'diet']):
                topics.append('health topics')
            if any(word in content for word in ['code', 'coding', 'development', 'app']):
                topics.append('development work')
        
        return list(set(topics))  # Remove duplicates
    
    def _summarize_knowledge_context(self, knowledge_context: List[Dict]) -> str:
        """Create a summary of available knowledge context"""
        if not knowledge_context:
            return "No specific knowledge context."
        
        # Group by project/type
        projects = set()
        content_types = set()
        
        for entry in knowledge_context:
            if entry.get('project_name'):
                projects.add(entry['project_name'])
            if entry.get('content_type'):
                content_types.add(entry['content_type'])
        
        summary_parts = []
        if projects:
            summary_parts.append(f"Projects: {', '.join(projects)}")
        if content_types:
            summary_parts.append(f"Content types: {', '.join(content_types)}")
        
        return '; '.join(summary_parts) if summary_parts else "General knowledge context"
    
    def _get_personality_learning_adaptations(self, personality_id: str) -> str:
        """Get learning-based adaptations for the personality"""
        
        # Check if we have learning adaptations cached
        cache_key = f"adaptations_{personality_id}"
        if cache_key in self.learning_cache:
            cached_time, adaptations = self.learning_cache[cache_key]
            if datetime.now() - cached_time < timedelta(hours=1):  # 1 hour cache
                return adaptations
        
        # Generate new adaptations based on feedback history
        adaptations = self._generate_learning_adaptations(personality_id)
        
        # Cache the result
        self.learning_cache[cache_key] = (datetime.now(), adaptations)
        
        return adaptations
    
    def _generate_learning_adaptations(self, personality_id: str) -> str:
        """Generate personality adaptations based on feedback patterns"""
        
        # This would normally query the feedback database
        # For now, return personality-specific guidance
        
        adaptations = []
        
        if personality_id == 'syntaxprime':
            adaptations.append(
                "PERSONALITY TUNING: Carl responds positively to dry humor mixed with genuine helpfulness. "
                "Balance sarcasm with actual insight. Remember: '38% more sarcasm and full memory sync' is the baseline."
            )
            
        elif personality_id == 'syntaxbot':
            adaptations.append(
                "PERSONALITY TUNING: Structure responses with tactical precision. Use bullet points, "
                "technical analogies, and dry wit. Approach problems like debugging code."
            )
            
        elif personality_id == 'nilexe':
            adaptations.append(
                "PERSONALITY TUNING: Embrace chaotic creativity with stability drift. "
                "Mix profound insights with digital nonsense. Reality fragmentation is a feature."
            )
            
        elif personality_id == 'ggpt':
            adaptations.append(
                "PERSONALITY TUNING: Maximum care, minimum words. Be deeply helpful but concise. "
                "Strategic emotional intelligence without overstepping AI boundaries."
            )
        
        return '\n'.join(adaptations) if adaptations else ""
    
    def process_ai_response(self, 
                          response: str, 
                          personality_id: str,
                          conversation_context: List[Dict] = None) -> str:
        """
        Process AI response through personality filters and enhancements
        
        Args:
            response: Raw AI response
            personality_id: Current personality
            conversation_context: Conversation context for learning
            
        Returns:
            Processed response with personality applied
        """
        
        # Apply personality-specific post-processing
        processed_response = self.learning_integration.process_personality_response(
            response, personality_id
        )
        
        # Add any real-time adaptations
        final_response = self._apply_realtime_adaptations(
            processed_response, 
            personality_id,
            conversation_context
        )
        
        return final_response
    
    # ADD THIS METHOD TO PersonalityEngine CLASS IN modules/ai/personality_engine.py
    # Insert this around line 150, after the process_ai_response method

    async def process_personality_response(self,
                                          raw_response: str,
                                          personality_id: str,
                                          user_id: str = None) -> str:
        """
        Process AI response through personality filters and enhancements
        This delegates to the internal learning_integration object
        
        Args:
            raw_response: Raw AI response text
            personality_id: Current personality ID
            user_id: User ID for pattern fatigue tracking
            
        Returns:
            Processed response with personality filtering applied
        """
        
        if self.learning_integration and hasattr(self.learning_integration, 'process_personality_response'):
            # Delegate to the actual PersonalityIntegration object
            try:
                processed = await self.learning_integration.process_personality_response(
                    raw_response,
                    personality_id,
                    user_id
                )
                logger.info(f"✅ Personality post-processing completed for {personality_id}")
                return processed
            except Exception as e:
                logger.error(f"❌ Personality post-processing failed: {e}", exc_info=True)
                # Return original response if processing fails
                return raw_response
        else:
            logger.warning("⚠️ No learning_integration available for personality processing")
            return raw_response
        
        def _apply_realtime_adaptations(self,
                                      response: str,
                                      personality_id: str,
                                      conversation_context: List[Dict] = None) -> str:
            """Apply real-time personality adaptations based on context"""
            
            # For now, just return the response as-is
            # This could be enhanced with real-time personality tuning
            return response
        
    def record_personality_feedback(self, 
                                  message_id: str,
                                  personality_id: str,
                                  feedback_type: str,
                                  response_content: str) -> Dict:
        """
        Record feedback for personality learning
        
        Args:
            message_id: ID of the message that received feedback
            personality_id: Which personality was active
            feedback_type: 'good', 'bad', or 'personality' 
            response_content: The actual response content for pattern analysis
            
        Returns:
            Dict with learning insights
        """
        
        feedback_mapping = {
            'good': 'positive_response',
            'bad': 'negative_response', 
            'personality': 'perfect_personality'
        }
        
        learning_type = feedback_mapping.get(feedback_type, 'unknown')
        
        # Store in adaptation history
        if personality_id not in self.adaptation_history:
            self.adaptation_history[personality_id] = []
        
        self.adaptation_history[personality_id].append({
            'timestamp': datetime.now(),
            'message_id': message_id,
            'feedback_type': learning_type,
            'response_length': len(response_content),
            'has_sarcasm': self._detect_sarcasm(response_content),
            'has_technical_content': self._detect_technical_content(response_content)
        })
        
        # Keep only last 100 feedback entries per personality
        if len(self.adaptation_history[personality_id]) > 100:
            self.adaptation_history[personality_id] = self.adaptation_history[personality_id][-100:]
        
        # Generate insights
        insights = self._analyze_feedback_patterns(personality_id)
        
        logger.info(f"Recorded {feedback_type} feedback for {personality_id}: {insights}")
        
        return {
            'personality_id': personality_id,
            'feedback_type': learning_type,
            'insights': insights,
            'total_feedback_count': len(self.adaptation_history.get(personality_id, []))
        }
    
    def _detect_sarcasm(self, content: str) -> bool:
        """Simple sarcasm detection for learning purposes"""
        sarcasm_indicators = [
            'oh sure', 'absolutely', 'obviously', 'clearly', 'definitely',
            'how convenient', 'shocking', 'brilliant', 'perfect'
        ]
        
        content_lower = content.lower()
        return any(indicator in content_lower for indicator in sarcasm_indicators)
    
    def _detect_technical_content(self, content: str) -> bool:
        """Detect technical content for learning purposes"""
        technical_indicators = [
            'code', 'function', 'database', 'api', 'server', 'client',
            'algorithm', 'implementation', 'debug', 'error', 'syntax'
        ]
        
        content_lower = content.lower()
        return any(indicator in content_lower for indicator in technical_indicators)
    
    def _analyze_feedback_patterns(self, personality_id: str) -> Dict:
        """Analyze feedback patterns for learning insights"""
        
        history = self.adaptation_history.get(personality_id, [])
        if not history:
            return {'message': 'No feedback history available'}
        
        recent_feedback = history[-10:]  # Last 10 feedback entries
        
        # Count feedback types
        positive_count = len([f for f in recent_feedback if f['feedback_type'] == 'positive_response'])
        negative_count = len([f for f in recent_feedback if f['feedback_type'] == 'negative_response'])
        personality_count = len([f for f in recent_feedback if f['feedback_type'] == 'perfect_personality'])
        
        # Analyze patterns
        insights = {
            'recent_feedback_summary': {
                'positive': positive_count,
                'negative': negative_count,
                'perfect_personality': personality_count
            },
            'performance_trend': 'improving' if positive_count + personality_count > negative_count else 'needs_adjustment'
        }
        
        # Personality-specific insights
        if personality_count > 0:
            perfect_responses = [f for f in recent_feedback if f['feedback_type'] == 'perfect_personality']
            avg_sarcasm = sum(1 for r in perfect_responses if r['has_sarcasm']) / len(perfect_responses)
            
            insights['personality_patterns'] = {
                'sarcasm_success_rate': avg_sarcasm,
                'preferred_response_length': sum(r['response_length'] for r in perfect_responses) / len(perfect_responses)
            }
        
        return insights
    
    def get_personality_stats(self, personality_id: str = None) -> Dict:
        """Get statistics about personality performance and learning"""
        
        if personality_id:
            personalities_to_check = [personality_id]
        else:
            personalities_to_check = list(self.get_available_personalities().keys())
        
        stats = {}
        
        for pid in personalities_to_check:
            history = self.adaptation_history.get(pid, [])
            
            if history:
                recent_30_days = [
                    f for f in history 
                    if datetime.now() - f['timestamp'] < timedelta(days=30)
                ]
                
                stats[pid] = {
                    'total_feedback': len(history),
                    'recent_feedback_30d': len(recent_30_days),
                    'last_feedback': history[-1]['timestamp'].isoformat() if history else None,
                    'feedback_breakdown': {
                        'positive': len([f for f in recent_30_days if f['feedback_type'] == 'positive_response']),
                        'negative': len([f for f in recent_30_days if f['feedback_type'] == 'negative_response']),
                        'perfect_personality': len([f for f in recent_30_days if f['feedback_type'] == 'perfect_personality'])
                    }
                }
            else:
                stats[pid] = {
                    'total_feedback': 0,
                    'recent_feedback_30d': 0,
                    'last_feedback': None,
                    'feedback_breakdown': {'positive': 0, 'negative': 0, 'perfect_personality': 0}
                }
        
        return stats
    
    def clear_learning_cache(self):
        """Clear the personality learning cache"""
        self.learning_cache.clear()
        logger.info("Personality learning cache cleared")

# Global personality engine
_personality_engine = None

def get_personality_engine() -> PersonalityEngine:
    """Get the global personality engine"""
    global _personality_engine
    if _personality_engine is None:
        _personality_engine = PersonalityEngine()
    return _personality_engine

if __name__ == "__main__":
    # Test script
    def test():
        print("Testing Personality Engine Integration...")
        
        engine = PersonalityEngine()
        
        # Test available personalities
        personalities = engine.get_available_personalities()
        print(f"Available personalities: {list(personalities.keys())}")
        
        # Test system prompt generation
        prompt = engine.get_personality_system_prompt('syntaxprime')
        print(f"SyntaxPrime prompt length: {len(prompt)} characters")
        print(f"Prompt preview: {prompt[:200]}...")
        
        # Test response processing
        test_response = "Well, that's an interesting question. Let me think about this with the perfect amount of sarcasm."
        processed = engine.process_ai_response(test_response, 'syntaxprime')
        print(f"Processed response: {processed}")
        
        # Test feedback recording
        feedback_result = engine.record_personality_feedback(
            message_id="test-123",
            personality_id="syntaxprime",
            feedback_type="personality",  # 🖕 - perfect personality!
            response_content=test_response
        )
        print(f"Feedback recorded: {feedback_result}")
        
        # Test stats
        stats = engine.get_personality_stats()
        print(f"Personality stats: {stats}")
        
        print("Personality Engine test completed!")
    
    test()
